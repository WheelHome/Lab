## 根据指标进行程序优化

这段时间一直在做一些对性能有所要求项目，因此从中也得到了一些调优的经验，权且记录一下

### 什么是优化

优化，一般说来就是让程序性能达到最优

但是，我感觉，优化并不单纯是让程序性能达到最优，而是让程序在性能与资源中达到一个最优的平衡

举个例子，一台服务器可能会跑多个服务，那么如果一个对QPS要求不是很高的服务，但是为了极致的性能，占用了服务器大量的资源，那么这种就不是正确的优化方式

这种情况下应该做的，就是降低程序的性能释放占用的资源，让其他服务能够使用

### 如何优化

优化，无非就是各项指标，例如CPU使用率，内存占用率，I/O吞吐量

最近我有在做一个hdfs相关的项目，大概就是将接收到的数据存放到hdfs中，由于数据的格式，在没有接受完所有数据之前，上传是不能进行的，而数据量又非常庞大，大概几十个G左右，而要求就是，不能一直占用太多的内存

这个要求，涉及到一个吞吐的问题，对于内存不能占用太多，我们可以把内存置换到硬盘中，但是这个置换，是需要时间的，而数据推的非常快，如何保证内存中的数据队列能够快速的置换到硬盘中？

```
data--->[ data | data | data ]-->(disk)
```

答案很简单，多线程

数据持久化的方案，我们使用的是 google 的 protobuf + leveldb，在接收到数据后，对其进行序列化，然后写入到leveldb中，这样一来，在整个过程中，程序的内存占用就会非常稳定，因为内存中的数据队列长度基本为0，没有拥堵自然不会占用内存

具体的方案是怎么得到的呢，如下

根据我的经验，序列化是非常消耗CPU的，如果一次序列化+写入使用了1ms，那么性能就无法接受了，因为，每一次推送的数据有1w个包，推送的间隔远远小于1s

不过，经验有可能是不可靠的，最佳的优化就是实事求是，以指标为导向进行

1. 使用单线程进行序列化+写入，打印每一次推送（1w个包）序列化，以及持久化到硬盘的时间，观察期间的内存使用情况以及CPU使用情况，这里推荐使用htop，htop可以反应 CPU 的两种占用情况，1）.正在被使用，2）.等待io，结果是单线程无法消化完内存中的数据队列，导致数据队列不断的累积，最后oom
2. 使用线程池的方式，将10000个数据分发到不同的线程中，分发的逻辑很简单，10000 / 线程数，余数归并到最后一个任务中，结果，序列化的时间以及符合吞吐的需要了，但是时间卡在了持久化上
3. 我们都知道，小文件读写的性能远低于同样大小的大文件读写的性能，因此，我们可以在持久化这里做一些功夫，也就是，当数据累积到一定程度的时候才进行写入操作，结果，整个流程都是很ok的，cpu和硬盘的性能都使用到了极致，cpu可以打满，而硬盘的读写也能到百兆/s级别，内存维持在一个比较低的状态

接收完了，然后就可以进行写入，这个过程，无论怎么优化，都是会占用非常大的内存空间的，毕竟要把数据全部加载，但是，可以对数据进行压缩，同样的，这个过程也采用了多线程的方案，读->压缩->清空原来的数据，这样以来，也可以保证不会占用太过于庞大的内存

整个的操作，都是建立在多线程的基础上的，因此，写出一个多线程友好的程序是非常重要的，也就是，这个程序的流程，可以非常方便地被改造为多线程

## 一些命令的使用心得

### 在服务器上观察程序状态

hdfs service写完之后，我将其部署到一台服务器上，在观察的过程中，也有一些小心得

一般，我在服务器上最关注的，就是hdfs service占用了多大的内存，一般我都会做一些操作，例如

```
ps ax | grep hdfs 得到pid，然后top -p pid -H 查看进程的资源使用状态
```

但是这个过程还是很花时间的，对于我这种手速不够快的人来说，每次都要手打pid简直太难了

其实，ps就可以很简单的看到内存的占用率，如`ps -aux | grep hdfs`

由于是以后台进程的形式运行的，观察运行状态只能看日志，so，贼好用的`watch`就来了

`watch -n 0 tail debug.log -n 100` 每0s执行次tail指令，这样就和直接debug看输出没啥区别了

配合tmux，一边top，一边watch，还是非常好用的

### 调优时用到的工具

首先htop不能少的，在开发的时候，因为没有其他service的干扰，因此，htop可以很直观的看到cpu的使用，这样就能定位到，是cpu不够快，还是io太慢了，从而找出内存数据队列膨胀的原因

iotop，可以简单的查看硬盘io速率，sar -n DEV 可以简单的查看网络io速率

